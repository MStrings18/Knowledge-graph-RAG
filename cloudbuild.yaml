# Final cloudbuild.yaml using public Docker Hub image

steps:
  # Step 1: SSH into the server to perform deployment tasks
  # CHANGE: Using the public image from Docker Hub to bypass gcr.io permissions
  - name: 'google/cloud-sdk:latest'
    entrypoint: 'gcloud'
    args:
      - 'compute'
      - 'ssh'
      - '--zone=us-central1-f'
      - 'kg-rag-prod'
      - '--command'
      - |
        # --- Create a persistent data directory (if it doesn't exist) ---
        mkdir -p /home/mananverma181195/persistent_data

        # Go to the project directory and pull the latest code
        cd Knowledge-graph-RAG
        git pull

        # --- Move the SQLite database to the persistent location ---
        mv backend/threads.db /home/mananverma181195/persistent_data/threads.db || true

        # --- Start the Neo4j Database using Docker ---
        echo "Starting Neo4j database..."
        # We need to install docker-compose first on the gcloud image
        apt-get update && apt-get install -y docker-compose
        docker-compose up -d

        # --- Run Backend ---
        echo "Starting backend..."
        cd backend
        # The public gcloud image does not have venv, so we run directly
        pip install -r requirements.txt
        
        # Kill any old Gunicorn process for a clean restart
        pkill gunicorn || true

        # Start Gunicorn with the Uvicorn worker for FastAPI
        THREADS_DB_PATH="/home/mananverma181195/persistent_data/threads.db" gunicorn --bind 0.0.0.0:8000 --workers 3 -k uvicorn.workers.UvicornWorker API:app --daemon
        cd ..
        
        echo "Backend deployment complete!"

# Timeout for the build process
timeout: '1200s'

# Explicitly set the logging option to fix the initial build error
options:
  logging: CLOUD_LOGGING_ONLY